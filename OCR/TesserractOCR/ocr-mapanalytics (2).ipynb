{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6841064,"sourceType":"datasetVersion","datasetId":3668476}],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!sudo apt-get install tesseract-ocr\n!pip install pytesseract","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-25T04:01:41.651966Z","iopub.execute_input":"2024-01-25T04:01:41.653239Z","iopub.status.idle":"2024-01-25T04:01:59.107021Z","shell.execute_reply.started":"2024-01-25T04:01:41.653197Z","shell.execute_reply":"2024-01-25T04:01:59.105773Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree       \nReading state information... Done\ntesseract-ocr is already the newest version (4.1.1-2build2).\n0 upgraded, 0 newly installed, 0 to remove and 73 not upgraded.\nRequirement already satisfied: pytesseract in /opt/conda/lib/python3.10/site-packages (0.3.10)\nRequirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.10/site-packages (from pytesseract) (21.3)\nRequirement already satisfied: Pillow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from pytesseract) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21.3->pytesseract) (3.0.9)\n","output_type":"stream"}]},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport cv2\nimport os\nfrom PIL import Image\nimport pytesseract\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2024-01-25T04:01:59.109515Z","iopub.execute_input":"2024-01-25T04:01:59.109874Z","iopub.status.idle":"2024-01-25T04:01:59.119800Z","shell.execute_reply.started":"2024-01-25T04:01:59.109841Z","shell.execute_reply":"2024-01-25T04:01:59.118146Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"map_data = {}\n\ndef add_map(map_id, value_id, color, lower_bound, upper_bound):\n    map_data[map_id][value_id] = {\n        \"color\": color,\n        \"lower_bound\": lower_bound,\n        \"upper_bound\": upper_bound\n    }","metadata":{"execution":{"iopub.status.busy":"2024-01-25T04:01:59.121699Z","iopub.execute_input":"2024-01-25T04:01:59.122057Z","iopub.status.idle":"2024-01-25T04:01:59.131763Z","shell.execute_reply.started":"2024-01-25T04:01:59.122028Z","shell.execute_reply":"2024-01-25T04:01:59.130586Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"image_files = [f for f in os.listdir(path=\"/kaggle/input/dv-pe/accuracy_images\") if f.endswith(('.png'))]\n\nmap_data_path = \"/kaggle/working/map_data.txt\"\n\ndef num_there(s):\n    return any(i.isdigit() for i in s)","metadata":{"execution":{"iopub.status.busy":"2024-01-25T04:01:59.134514Z","iopub.execute_input":"2024-01-25T04:01:59.134863Z","iopub.status.idle":"2024-01-25T04:01:59.147024Z","shell.execute_reply.started":"2024-01-25T04:01:59.134834Z","shell.execute_reply":"2024-01-25T04:01:59.145688Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def mask(image):\n    x, y, w, h = 188, 17, 283, 32\n\n    x = x - (w//2)\n    y = y - (h//2)\n\n    # Create a mask\n    mask = np.ones_like(image) * 255  # White mask\n\n    # Draw a black rectangle on the mask to cover the region outside the bounding box\n    cv2.rectangle(mask, (x, y), (x + w, y + h), (0, 0, 0), thickness=cv2.FILLED)\n\n    # Bitwise AND operation to apply the mask\n    image = cv2.bitwise_and(image, mask)\n\n    # Display the original image and the masked image using matplotlib\n    plt.figure(figsize=(10, 5))\n\n    # plt.subplot(1, 2, 1)\n    # plt.imshow(cv2.cvtColor(images, cv2.COLOR_BGR2RGB))\n    # plt.title(\"Original Image\")\n    # plt.axis(\"off\")\n\n#     plt.subplot(1, 2, 2)\n#     plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n#     plt.title(\"Masked Image\")\n#     plt.axis(\"off\")\n\n#     plt.show()\n    \n    return image","metadata":{"execution":{"iopub.status.busy":"2024-01-25T04:01:59.148529Z","iopub.execute_input":"2024-01-25T04:01:59.149830Z","iopub.status.idle":"2024-01-25T04:01:59.159368Z","shell.execute_reply.started":"2024-01-25T04:01:59.149784Z","shell.execute_reply":"2024-01-25T04:01:59.157956Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"for image in image_files:\n    image_dir = \"/kaggle/input/dv-pe/accuracy_images\"\n    image_path = os.path.join(image_dir, image)\n    # Argument Parser\n    args = {\"image\": image_path, \"pre_processor\": \"thresh\"}  # Replace with your image path\n\n    # print(map_name)\n    # Reading the image with text\n    images = cv2.imread(args[\"image\"])\n    image_rgb = cv2.cvtColor(images, cv2.COLOR_BGR2RGB)\n\n    # Converting to grayscale image\n    gray = cv2.cvtColor(images, cv2.COLOR_BGR2GRAY)\n\n    # performing preprocessing techniques of threshing and/or blurring.\n    if args[\"pre_processor\"] == \"thresh\":\n        gray = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n    if args[\"pre_processor\"] == \"blur\":\n        gray = cv2.medianBlur(gray, 3)\n\n    # adding image to memory\n    # filename = \"{}.png\".format(os.getpid())\n    # cv2.imwrite(filename, gray)\n    # text = pytesseract.image_to_string(Image.open(filename))\n    # print(text)\n\n    images = mask(images)\n    \n    plt.subplot(1, 2, 2)\n    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n    plt.title(\"Masked Image\")\n    plt.axis(\"off\")\n\n    plt.show()\n\n    filename = \"{}.png\".format(os.getpid())\n    # print(filename)\n    cv2.imwrite(filename, gray)\n\n    data = pytesseract.image_to_data(Image.open(filename), output_type=pytesseract.Output.DICT)\n\n    # Looping over the detected text and the bounding boxes\n    for i in range(len(data[\"text\"])):\n        value_id = 0\n        if data[\"text\"][i].strip() != \"\":\n            x, y, w, h = data[\"left\"][i], data[\"top\"][i], data[\"width\"][i], data[\"height\"][i]\n            # cv2.rectangle(images, (x, y), (x + w, y + h), (0, 255, 0), 2)\n\n            text = data[\"text\"][i]\n            # print(f\"Text: {text}, Bounding Box: {x}, {y}, {w}, {h}\")\n\n            if num_there(text)==1:\n                value_id += 1\n                # print(type(text))\n                # print(f\"Text: {text}, Bounding Box: {x}, {y}, {w}, {h}\")\n                # cv2.rectangle(images, (x, y), (x + w, y + h), (0, 255, 0), 2)\n\n                x1 = x\n                x2 = x\n                y1 = y + h // 2\n                y2 = y + h // 2 - 1\n\n                while all(images[y1, x1]==images[y2, x2]):\n                    x2-=1\n                x2-=10\n\n                color = images[y2,x2]\n                # print(color)\n                # cv2.rectangle(images, (x2, y2), (x2+5, y2+5), (0, 255, 0), 2)\n\n                values = text.split(\"-\")\n                # print(values)\n\n                if len(values)==1:\n                    lower_bound = values[0]\n                    upper_bound = values[0]\n                else:\n                    lower_bound = values[0]\n                    upper_bound = values[1]\n\n                blue, green, red = color\n                print(f\"Blue: {blue}, Green: {green}, Red: {red}\")\n\n                # add_map(map_id, value_id, (blue, green, red), lower_bound, upper_bound)\n                # print(map_data)\n\n                map_name = \"map_\"+image[4:-4]\n                if map_name in map_data:\n                    map_data[map_name][value_id] = {\n                        \"color\": (blue, green, red),\n                        \"lower_bound\": lower_bound,\n                        \"upper_bound\": upper_bound,\n                    }\n                else:\n                    map_data[map_name] = {\n                        value_id: {\n                            \"color\": (blue, green, red),\n                            \"lower_bound\": lower_bound,\n                            \"upper_bound\": upper_bound,\n                        }\n                    }\n\n                with open(map_data_path, 'a') as f2:\n                    f2.write(map_name+\":\")\n                    f2.write(str(value_id)+\":(\")\n                    f2.write(str(blue)+\",\"+str(green)+\",\"+str(red)+\"),\")\n                    f2.write(str(lower_bound)+\",\")\n                    f2.write(str(upper_bound))\n                    f2.write(\"\\n---------------------\\n\")\n#                 print(map_data)\n\n                # color = images[y,x-25] # have to edit this to get the exact colour.\n                # print(f'Color at ({x}, {y}): {color}')\n\nos.remove(filename)\n# plt.imshow(cv2.cvtColor(images, cv2.COLOR_BGR2RGB))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}